{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute SAFs from DoseByRegions.txt and fill the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(server, user, password, db, host='localhost'):\n",
    "    '''Returns a connection and a metadata object'''\n",
    "    # We connect with the help of the URL\n",
    "    # postgresql://postgres:postgres@localhost:5432/opendose\n",
    "    url = '{}://{}:{}@{}/{}'\n",
    "    url = url.format(server, user, password, host, db)\n",
    "\n",
    "    # The return value of create_engine() is our connection object\n",
    "    con = sqlalchemy.create_engine(url)#, client_encoding='utf8')\n",
    "    # We then bind the connection to MetaData()\n",
    "    meta = sqlalchemy.MetaData(bind=con) #, reflect=True)\n",
    "    meta.reflect()\n",
    "\n",
    "    return con, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_single_sql_query(df, col_id, table, con):\n",
    "    '''Returns index of a column from a sql query'''\n",
    "    res = []\n",
    "    # allow only single df line query\n",
    "    if len(df.index) != 1:\n",
    "        return None\n",
    "    # compose the sql query from the df dataframe\n",
    "    sql='SELECT '+col_id+' FROM '+table+' WHERE '\n",
    "    for col in df.columns:\n",
    "        if col is not col_id:\n",
    "            sql += col+\"='\"+df[col].iloc[0]+\"' AND \"\n",
    "    sql = sql[:-5]+';'\n",
    "    # execute the sql query on the database table\n",
    "    for line in con.execute(sql):\n",
    "        res.append(line[col_id])\n",
    "    # return the index corresponding to the sql query (if one)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to the OpenDose database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://postgres:***@crctcalcul/opendose)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con, meta = connect(server='postgresql', user='postgres', password='CRCT_eq15', db='opendose', host='crctcalcul')\n",
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read tables from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provenance_id</th>\n",
       "      <th>provider</th>\n",
       "      <th>code</th>\n",
       "      <th>version</th>\n",
       "      <th>contact</th>\n",
       "      <th>email</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2019-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2018-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>SGH</td>\n",
       "      <td>GATE</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Erin McKay</td>\n",
       "      <td>erin@computerhead.com.au</td>\n",
       "      <td>2018-09-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>IEO-CNAO</td>\n",
       "      <td>FLUKA</td>\n",
       "      <td>2011</td>\n",
       "      <td>Francesca Botta</td>\n",
       "      <td>francesca.botta@ieo.it</td>\n",
       "      <td>2018-12-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2017-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>CRUK</td>\n",
       "      <td>PENELOPE</td>\n",
       "      <td>2014</td>\n",
       "      <td>Nadia Falzone</td>\n",
       "      <td>nadia.falzone@oncology.ox.ac.uk</td>\n",
       "      <td>2017-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SGH</td>\n",
       "      <td>GATE</td>\n",
       "      <td>7.2</td>\n",
       "      <td>Erin McKay</td>\n",
       "      <td>erin@computerhead.com.au</td>\n",
       "      <td>2018-06-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2019-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>CRCT</td>\n",
       "      <td>GATE</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Maxime Chauvin</td>\n",
       "      <td>maxime.chauvin@inserm.fr</td>\n",
       "      <td>2019-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    provenance_id  provider      code version          contact  \\\n",
       "29             30      CRCT      GATE     8.1   Maxime Chauvin   \n",
       "34             35      CRCT      GATE     8.1   Maxime Chauvin   \n",
       "12             13       SGH      GATE     7.2       Erin McKay   \n",
       "14             15  IEO-CNAO     FLUKA    2011  Francesca Botta   \n",
       "13             14      CRCT      GATE     8.0   Maxime Chauvin   \n",
       "15             16      CRUK  PENELOPE    2014    Nadia Falzone   \n",
       "38             39      CRCT      GATE     8.1   Maxime Chauvin   \n",
       "4               5       SGH      GATE     7.2       Erin McKay   \n",
       "44             45      CRCT      GATE     8.1   Maxime Chauvin   \n",
       "20             21      CRCT      GATE     8.1   Maxime Chauvin   \n",
       "\n",
       "                              email       date  \n",
       "29         maxime.chauvin@inserm.fr 2019-01-20  \n",
       "34         maxime.chauvin@inserm.fr 2018-12-12  \n",
       "12         erin@computerhead.com.au 2018-09-11  \n",
       "14           francesca.botta@ieo.it 2018-12-04  \n",
       "13         maxime.chauvin@inserm.fr 2017-08-31  \n",
       "15  nadia.falzone@oncology.ox.ac.uk 2017-09-08  \n",
       "38         maxime.chauvin@inserm.fr 2019-01-10  \n",
       "4          erin@computerhead.com.au 2018-06-06  \n",
       "44         maxime.chauvin@inserm.fr 2019-04-12  \n",
       "20         maxime.chauvin@inserm.fr 2019-01-13  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this load all the tables into memory, it's not adapted for large tables like t_safs\n",
    "t_pro = pd.read_sql('t_provenances', con)\n",
    "t_pha = pd.read_sql('t_phantoms', con)\n",
    "t_reg = pd.read_sql('t_regions', con)\n",
    "t_par = pd.read_sql('t_particles', con)\n",
    "\n",
    "pha = {}\n",
    "reg = {}\n",
    "par = {}\n",
    "# build dictionary of region_id for fast queries\n",
    "for i,p in t_pha.iterrows():\n",
    "    pha[p.model] = p.phantom_id\n",
    "    if p.model not in reg: reg[p.model] = {}\n",
    "    regions = t_reg[t_reg.phantom_id==p.phantom_id]\n",
    "    for j,r in regions.iterrows():\n",
    "        reg[p.model][r.region] = {'id': r.region_id, 'mass_g': r.mass_g}\n",
    "for i,p in t_par.iterrows():\n",
    "    par[p['name']] = p.particle_id\n",
    "\n",
    "# t_reg[t_reg.phantom_id==1].to_csv('/home/gate/Downloads/regions_AF.csv',index=False)\n",
    "t_pro.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read SAF results related to a specific code from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = {'provider':['CRCT'],\n",
    "       'code':['GATE'],\n",
    "       'version':['8.1'],\n",
    "       'contact':['Maxime Chauvin'],\n",
    "       'email':['maxime.chauvin@inserm.fr']}\n",
    "entry_pro_df = pd.DataFrame(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM t_safs WHERE provenance_id=19\n",
      "SELECT * FROM t_safs WHERE provenance_id=20\n",
      "SELECT * FROM t_safs WHERE provenance_id=21\n",
      "SELECT * FROM t_safs WHERE provenance_id=22\n",
      "SELECT * FROM t_safs WHERE provenance_id=23\n",
      "SELECT * FROM t_safs WHERE provenance_id=24\n",
      "SELECT * FROM t_safs WHERE provenance_id=25\n",
      "SELECT * FROM t_safs WHERE provenance_id=26\n",
      "SELECT * FROM t_safs WHERE provenance_id=27\n",
      "SELECT * FROM t_safs WHERE provenance_id=28\n",
      "SELECT * FROM t_safs WHERE provenance_id=29\n",
      "SELECT * FROM t_safs WHERE provenance_id=30\n",
      "SELECT * FROM t_safs WHERE provenance_id=31\n",
      "SELECT * FROM t_safs WHERE provenance_id=32\n",
      "SELECT * FROM t_safs WHERE provenance_id=33\n",
      "SELECT * FROM t_safs WHERE provenance_id=34\n",
      "SELECT * FROM t_safs WHERE provenance_id=35\n",
      "SELECT * FROM t_safs WHERE provenance_id=36\n",
      "SELECT * FROM t_safs WHERE provenance_id=37\n",
      "SELECT * FROM t_safs WHERE provenance_id=38\n",
      "SELECT * FROM t_safs WHERE provenance_id=39\n",
      "SELECT * FROM t_safs WHERE provenance_id=40\n",
      "SELECT * FROM t_safs WHERE provenance_id=41\n",
      "SELECT * FROM t_safs WHERE provenance_id=42\n",
      "SELECT * FROM t_safs WHERE provenance_id=43\n",
      "SELECT * FROM t_safs WHERE provenance_id=44\n",
      "SELECT * FROM t_safs WHERE provenance_id=45\n",
      "SELECT * FROM t_safs WHERE provenance_id=46\n"
     ]
    }
   ],
   "source": [
    "# get data from CRCT GATE 8.1 related to OpenDose calcul project with gilles.mathieu@inserm.fr\n",
    "sql  = \"SELECT provenance_id FROM t_provenances WHERE provider='\"+pro['provider'][0]\n",
    "sql += \"' AND code='\"+pro['code'][0]+\"' AND version='\"+pro['version'][0]+\"'\"\n",
    "provenance_id = pd.read_sql(sql, con).provenance_id.values\n",
    "\n",
    "saf_df = pd.DataFrame()\n",
    "for p in provenance_id:\n",
    "    sql = 'SELECT * FROM t_safs WHERE provenance_id='+str(p)\n",
    "    print(sql)\n",
    "    df = pd.read_sql(sql, con)\n",
    "    if saf_df.empty: saf_df = df\n",
    "    else: saf_df = saf_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provenance_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>particle_id</th>\n",
       "      <th>energy_MeV</th>\n",
       "      <th>saf</th>\n",
       "      <th>saf_std</th>\n",
       "      <th>nb_primaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188518</th>\n",
       "      <td>32</td>\n",
       "      <td>150</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167332</th>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116728</th>\n",
       "      <td>37</td>\n",
       "      <td>81</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116478</th>\n",
       "      <td>23</td>\n",
       "      <td>279</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178236</th>\n",
       "      <td>27</td>\n",
       "      <td>270</td>\n",
       "      <td>279</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>4.411645e-01</td>\n",
       "      <td>3.290050e-04</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105148</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>149</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59782</th>\n",
       "      <td>28</td>\n",
       "      <td>311</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56948</th>\n",
       "      <td>33</td>\n",
       "      <td>98</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>3.651024e-09</td>\n",
       "      <td>3.651024e-09</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188759</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>9.837703e-05</td>\n",
       "      <td>3.945829e-06</td>\n",
       "      <td>100000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        provenance_id  source_id  target_id  particle_id  energy_MeV  \\\n",
       "188518             32        150         23            2      0.0200   \n",
       "167332             36         38          5            1      0.0090   \n",
       "116728             37         81        137            2      0.0080   \n",
       "116478             23        279        206            2      0.0060   \n",
       "1427               36         61         39            2      0.0600   \n",
       "178236             27        270        279            1      0.0100   \n",
       "105148             34          5        149            2      0.0050   \n",
       "59782              28        311        294            1      0.0085   \n",
       "56948              33         98        165            1      0.0100   \n",
       "188759             35          3         96            1      0.0260   \n",
       "\n",
       "                 saf       saf_std  nb_primaries  \n",
       "188518  0.000000e+00  0.000000e+00   100000000.0  \n",
       "167332  0.000000e+00  0.000000e+00   100000000.0  \n",
       "116728  0.000000e+00  0.000000e+00   100000000.0  \n",
       "116478  0.000000e+00  0.000000e+00   100000000.0  \n",
       "1427    0.000000e+00  0.000000e+00   100000000.0  \n",
       "178236  4.411645e-01  3.290050e-04   100000000.0  \n",
       "105148  0.000000e+00  0.000000e+00   100000000.0  \n",
       "59782   0.000000e+00  0.000000e+00   100000000.0  \n",
       "56948   3.651024e-09  3.651024e-09   100000000.0  \n",
       "188759  9.837703e-05  3.945829e-06   100000000.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saf_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Walk the directories to find new results and fill the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AF 95 electrons\n",
      "AF 95 photons\n",
      "AF 10 electrons\n",
      "AF 10 photons\n"
     ]
    }
   ],
   "source": [
    "# results directory\n",
    "dbr_dir = '/home/gate/Downloads/dosebyregions_test/'\n",
    "\n",
    "# loop over results\n",
    "for model in os.listdir(dbr_dir):\n",
    "    for source in os.listdir(dbr_dir+'/'+model):\n",
    "        for particle in os.listdir(dbr_dir+'/'+model+'/'+source):\n",
    "            print(model, source, particle)\n",
    "            # get the corresponding id from the database\n",
    "            source_id = reg[model][int(source)]['id']\n",
    "            particle_id = par[particle]\n",
    "            # make sql query here on source_id and particle_id\n",
    "            if not saf_df.empty:\n",
    "                sp_df = saf_df[(saf_df.source_id == source_id) &\n",
    "                               (saf_df.particle_id == particle_id)]\n",
    "            else:\n",
    "                sp_df = pd.DataFrame()\n",
    "\n",
    "            for subdir, dirs, files in os.walk(dbr_dir+'/'+model+'/'+source+'/'+particle):\n",
    "                if 'DoseByRegions.txt' in files:\n",
    "                    # get model, source, particle, energy, nb_primaries from the directory name\n",
    "                    dirname = subdir.split('/')[-2].split('_')\n",
    "                    energy_MeV = float(dirname[3])\n",
    "                    nb_primaries = int(dirname[4])\n",
    "                    # check if this entry exist in the database\n",
    "                    # (checking this for all targets takes too much time) ?\n",
    "                    if not sp_df.empty:\n",
    "                        sel_df = sp_df[(sp_df.energy_MeV == energy_MeV) &\n",
    "                                       #(sp_df.target_id == target_id) &\n",
    "                                       (sp_df.nb_primaries == nb_primaries)]\n",
    "                    else:\n",
    "                        sel_df = pd.DataFrame()\n",
    "\n",
    "                    # if the entry is not in the database fill it\n",
    "                    if sel_df.empty:\n",
    "                        # get the date from the modification date of the file\n",
    "                        file_time = os.path.getmtime(subdir+'/DoseByRegions.txt')\n",
    "                        entry_pro_df['date'] = datetime.datetime.fromtimestamp(file_time).strftime(\"%Y-%m-%d\")\n",
    "                        # check if this provenance already exist, if not fill the database\n",
    "                        pro_id = df_single_sql_query(entry_pro_df,'provenance_id','t_provenances',con)\n",
    "                        if not pro_id:\n",
    "                            entry_pro_df.to_sql('t_provenances', con, if_exists='append', index=False)\n",
    "                            pro_id = df_single_sql_query(entry_pro_df,'provenance_id','t_provenances',con)\n",
    "\n",
    "                        # read the data for all the targets from DoseByRegions.txt\n",
    "                        dbr_data = pd.read_csv(subdir+'/DoseByRegions.txt', sep='\\s+')\n",
    "                        # create a new df with the entry data to fill the database with df.to_sql()\n",
    "                        new_df = pd.DataFrame(columns=saf_df.columns)\n",
    "                        entry = {}\n",
    "                        for i,row in dbr_data.iterrows():\n",
    "                            target_id = reg[model][int(row['#id'])]['id']\n",
    "                            target_kg = reg[model][int(row['#id'])]['mass_g'] /1000.\n",
    "                            entry['provenance_id'] = pro_id\n",
    "                            entry['source_id'] = source_id\n",
    "                            entry['target_id'] = target_id\n",
    "                            entry['particle_id'] = particle_id\n",
    "                            entry['energy_MeV'] = energy_MeV\n",
    "                            entry['saf'] = row['edep(MeV)']/target_kg/energy_MeV/nb_primaries\n",
    "                            entry['saf_std'] = row['std_edep']*entry['saf']\n",
    "                            entry['nb_primaries'] = nb_primaries\n",
    "                            new_df = new_df.append(pd.DataFrame(entry))\n",
    "                            # print(sel_df[sel_df.target_id == target_id][['saf','saf_std']])\n",
    "                        if not new_df.empty:\n",
    "                            try:\n",
    "                                # fill the database with this entry\n",
    "                                print('... filling the database with',subdir.split('/')[-2])\n",
    "                                #new_df.to_sql('t_safs', con, if_exists='append', index=False)\n",
    "                            except:\n",
    "                                print('Error: the database has refused the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...cleaning NPL EGS++ 2016\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=1\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=18\n",
      "...cleaning SCK.CEN MCNPX 2.7\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=2\n",
      "...cleaning IRSN MCNPX 2.6c\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=3\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=4\n",
      "...cleaning SGH GATE 7.2\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=5\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=6\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=7\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=8\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=9\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=10\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=11\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=12\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=13\n",
      "...cleaning CRCT GATE 8.0\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=14\n",
      "...cleaning IEO-CNAO FLUKA 2011\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=15\n",
      "...cleaning CRUK PENELOPE 2014\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=16\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=47\n",
      "3808 to delete...\n",
      "3808 duplicate rows in t_safs have been deleted.\n",
      "...cleaning CRCT GATE 8.1\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=19\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=20\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=21\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=22\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=23\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=24\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=25\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=26\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=27\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=28\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=29\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=30\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=31\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=32\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=33\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=34\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=35\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=36\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=37\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=38\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=39\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=40\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=41\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=42\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=43\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=44\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=45\n",
      "SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs WHERE provenance_id=46\n"
     ]
    }
   ],
   "source": [
    "# clean by code to be sure there is one entry per source, target, energy\n",
    "t_pro = pd.read_sql('t_provenances', con)\n",
    "t_pro['code_version'] = t_pro['provider'] + ' ' + t_pro['code'] + ' ' + t_pro['version']\n",
    "\n",
    "codes = {}\n",
    "for i,row in t_pro.iterrows():\n",
    "    code = row['code_version']\n",
    "    if code not in codes: \n",
    "        codes[code] = [row['provenance_id']]\n",
    "    else:\n",
    "        codes[code].append(row['provenance_id'])\n",
    "\n",
    "for code,pro_id in codes.items():\n",
    "    # to skip some codes\n",
    "    if (code == 'CRCT Geant4 10.5'): continue\n",
    "    print('...cleaning', code)\n",
    "    saf_df = pd.DataFrame()\n",
    "    for p in pro_id:\n",
    "        sql  = 'SELECT ctid, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs'\n",
    "        sql += ' WHERE provenance_id='+str(p)\n",
    "        print(sql)\n",
    "        df = pd.read_sql(sql, con)\n",
    "        if saf_df.empty: saf_df = df\n",
    "        else: saf_df = saf_df.append(df)\n",
    "    badctid = saf_df[saf_df.duplicated(keep='last',\n",
    "        subset=['source_id', 'target_id', 'particle_id', 'energy_MeV', 'nb_primaries'])].ctid\n",
    "\n",
    "    if not badctid.empty:\n",
    "        # delete the duplicate entries of this code\n",
    "        print(len(badctid),'to delete...')\n",
    "#         sql = 'DELETE FROM t_safs WHERE ctid IN '+str(tuple(badctid))\n",
    "#         result = con.execute(sql)\n",
    "#         print (result.rowcount,'duplicate rows in t_safs have been deleted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT COUNT(*) FROM t_safs; = 11177347 (2019-05-06)\n",
    "# SELECT COUNT(*) FROM t_safs; = 12608488 (2020-01-06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ********************* remove exact duplicates in t_safs *********************\n",
    "# # *****************************************************************************\n",
    "# # delete rows in the list of bad ctid (shorter)\n",
    "# sql = '''\n",
    "# DELETE FROM t_safs a USING \n",
    "# (SELECT max(ctid) AS badctid FROM t_safs GROUP BY t_safs.* HAVING COUNT(*) > 1) b \n",
    "# WHERE a.ctid IN (badctid)\n",
    "# '''\n",
    "# result = con.execute(sql)\n",
    "# print (result.rowcount,'duplicate rows in t_safs have been deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to see only a limited number of rows\n",
    "# SELECT * FROM t_safs LIMIT 10;\n",
    "\n",
    "# # check duplicates\n",
    "# SELECT * FROM t_safs GROUP BY t_safs.* HAVING (COUNT(*) > 1);\n",
    "# # check duplicates with different saf or saf_std\n",
    "# SELECT provenance_id, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries FROM t_safs GROUP BY provenance_id, source_id, target_id, particle_id, \"energy_MeV\", nb_primaries HAVING (COUNT(*) > 1);\n",
    "# SELECT max(ctid) AS badctid FROM t_safs GROUP BY t_safs.* HAVING COUNT(*) > 1;\n",
    "\n",
    "# # delete entries\n",
    "# DELETE FROM t_safs WHERE provenance_id=xxx;\n",
    "# DELETE FROM t_provenances WHERE provenance_id=xxx;\n",
    "\n",
    "# # reset the primary key auto increment value after deleting entries\n",
    "# ALTER SEQUENCE t_provenances_provenance_id_seq RESTART WITH xxx;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dictionary of results related to a specific code from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # get data from CRCT GATE 8.1 related to OpenDose calcul project with gilles.mathieu@inserm.fr\n",
    "# sql  = \"SELECT provenance_id FROM t_provenances WHERE provider='\"+pro['provider'][0]\n",
    "# sql += \"' AND code='\"+pro['code'][0]+\"' AND version='\"+pro['version'][0]+\"'\"\n",
    "# provenance_id = pd.read_sql(sql, con).provenance_id.values\n",
    "\n",
    "# saf_df = pd.DataFrame()\n",
    "# for p in provenance_id:\n",
    "#     sql = 'SELECT * FROM t_safs WHERE provenance_id='+str(p)\n",
    "#     df = pd.read_sql(sql, con)\n",
    "#     if saf_df.empty:\n",
    "#         print(sql)\n",
    "#         saf_df = df\n",
    "#     else:\n",
    "#         print(sql)\n",
    "#         saf_df = saf_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saf_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # time = ~1 min per million rows\n",
    "# db = {'source':{'target':{'particle':{'energy':'nb_primaries'}}}}\n",
    "\n",
    "# for i,row in saf_df.iterrows():\n",
    "#     if row.source_id not in db: \n",
    "#         db[row.source_id] = {}\n",
    "#     if row.target_id not in db[row.source_id]: \n",
    "#         db[row.source_id][row.target_id] = {}\n",
    "#     if row.particle_id not in db[row.source_id][row.target_id]: \n",
    "#         db[row.source_id][row.target_id][row.particle_id] = {}\n",
    "#     db[row.source_id][row.target_id][row.particle_id][row.energy_MeV] = row.nb_primaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/home/gate/OpenDose/db_GATE8.1.json', 'w') as f:\n",
    "#     json.dump(db, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Walk the directories to compute SAFs from DoseByRegions.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro = {'provider':['CRCT'],\n",
    "#        'code':['GATE'],\n",
    "#        'version':['8.1'],\n",
    "#        'contact':['Maxime Chauvin'],\n",
    "#        'email':['maxime.chauvin@inserm.fr']}\n",
    "# entry_pro_df = pd.DataFrame(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # physic constants\n",
    "# Joules_MeV = 1.602176565e-13 # MeV in Joules\n",
    "\n",
    "# # results directory\n",
    "# # dbr_dir = '/home/gate/Downloads/dosebyregions_test/'\n",
    "# dbr_dir = '/home/gate/Downloads/dosebyregions/'\n",
    "\n",
    "# # loop over results\n",
    "# for subdir, dirs, files in os.walk(dbr_dir):\n",
    "#     if 'DoseByRegions.txt' in files:\n",
    "#         # get model, source, particle, energy, nb_primaries from the directory name\n",
    "#         dirname = subdir.split('/')[-2].split('_')\n",
    "#         model, source, particle, energy, nb = dirname[0], dirname[1], dirname[2], dirname[3], dirname[4]\n",
    "#         if particle == 'gamma': particle = 'photons'\n",
    "#         if particle == 'e-': particle = 'electrons'\n",
    "#         print(model, source, particle, energy, nb)\n",
    "#         # get the corresponding id from the database\n",
    "#         phantom_id = pha[model]\n",
    "#         if int(source) not in reg[model]: \n",
    "#             print('caca')\n",
    "#             continue\n",
    "#         source_id = reg[model][int(source)]\n",
    "#         particle_id = par[particle]\n",
    "#         energy_MeV = float(energy)\n",
    "#         nb_primaries = int(nb)\n",
    "#         # print(source_id, particle_id, energy_MeV, nb_primaries)\n",
    "        \n",
    "#         # read the data for all the targets from DoseByRegions.txt\n",
    "#         dbr_data = pd.read_csv(subdir+'/DoseByRegions.txt', sep='\\s+')\n",
    "#         # get the date from the modification date of the file\n",
    "#         file_time = os.path.getmtime(subdir+'/DoseByRegions.txt')\n",
    "#         entry_pro_df['date'] = datetime.datetime.fromtimestamp(file_time).strftime(\"%Y-%m-%d\")\n",
    "#         # check if this provenance already exist, if not fill the database\n",
    "#         pro_id = df_single_sql_query(entry_pro_df,'provenance_id','t_provenances',con)\n",
    "#         if not pro_id:\n",
    "#             entry_pro_df.to_sql('t_provenances', con, if_exists='append', index=False)\n",
    "#             pro_id = df_single_sql_query(entry_pro_df,'provenance_id','t_provenances',con)\n",
    "        \n",
    "#         # check if this entry exist in the database (checking this for all targets takes too much time)\n",
    "#         # build dictionary to make this faster, first make a list of files to add, sorted by source \n",
    "#         # and build dictionary with sql query on this source\n",
    "#         if not saf_df.empty:\n",
    "#             sel_df = saf_df[(saf_df.source_id == source_id) &\n",
    "#                             # (saf_df.target_id == target_id) &\n",
    "#                             (saf_df.particle_id == particle_id) &\n",
    "#                             (saf_df.energy_MeV == energy_MeV) &\n",
    "#                             (saf_df.nb_primaries == nb_primaries)]\n",
    "#         else:\n",
    "#             sel_df = pd.DataFrame()\n",
    "#         # if the entry is not in the database fill it\n",
    "#         if sel_df.empty:\n",
    "#             # create a new df with the entry data to fill the database with df.to_sql()\n",
    "#             new_df = pd.DataFrame(columns=saf_df.columns)\n",
    "#             entry = {}\n",
    "#             for i,row in dbr_data.iterrows():\n",
    "#                 target_id = reg[model][int(row['#id'])]\n",
    "#                 entry['provenance_id'] = pro_id\n",
    "#                 entry['source_id'] = source_id\n",
    "#                 entry['target_id'] = target_id\n",
    "#                 entry['particle_id'] = particle_id\n",
    "#                 entry['energy_MeV'] = energy_MeV\n",
    "#                 entry['saf'] = row['dose(Gy)']/(energy_MeV*Joules_MeV)/nb_primaries\n",
    "#                 entry['saf_std'] = row['std_dose']*entry['saf']\n",
    "#                 entry['nb_primaries'] = nb_primaries\n",
    "#                 new_df = new_df.append(pd.DataFrame(entry))\n",
    "#                 # print(sel_df[sel_df.target_id == target_id][['saf','saf_std']])\n",
    "#             if not new_df.empty:\n",
    "#                 try:\n",
    "#                     # fill the database with this entry\n",
    "#                     print('... filling the database with',subdir.split('/')[-2])\n",
    "#                     new_df.to_sql('t_safs', con, if_exists='append', index=False)\n",
    "#                 except:\n",
    "#                     print('Error: the database has refused the data')\n",
    "\n",
    "# # entry_pro_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
